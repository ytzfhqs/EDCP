# 时效性 

- **模型和评估数据集的时效性**：模型频繁更新微调，但预训练相对较少，导致 NLP 社区依赖少数静态预训练模型。语言使用随时间变化，预训练和评估数据时间不匹配会导致性能下降，且该影响无法通过微调完全消除。 

- **对模型的影响**：

   ■  过拟合风险：模型可能过度拟合特定时间段的数据特征，导致在新数据上的泛化能力下降。

   ■  资源消耗：大模型的训练和计算成本更高，时间错位可能导致资源浪费。 

   ■  优化挑战：寻找最优的预训练时间和数据更新策略变得更加困难。

   ■  性能波动：模型在不同时间的评估任务上的性能表现不稳定。    

# 质量过滤器和毒性过滤器 

  - 对模型行为的影响：质量和毒性过滤器对模型行为有显著但相反的影响。

   - 质量过滤器： 

        - 提升性能：尽管减少了训练数据的数量和多样性，但能显著提高几乎所有下游任务的性能，包括毒性识别（提高约 2%）和大多数问答任务类别（提高 1 - 6%）。  

        -  意外发现：去除了大量训练数据，但性能仍有所提升，这表明质量过滤器可能捕捉到了数据中与任务相关的重要特征。 

        - 领域差异：对不同领域的任务效果不同，例如对 Books 领域的问答任务效果不明显，甚至有负面影响，但对学术和生物医学等领域的任务有较大提升。 

        - 质量预测难题：数据的观测质量特征不足以预测哪些领域将从质量过滤中受益最多，这表明质量过滤的效果不仅仅取决于去除低质量数据的数量，还可能与其他质量方面的因素有关，如最高或中等质量数据的代表性。  

   - 毒性过滤器：

    ■  毒性生成与识别的权衡：使用毒性分类器进行过滤会导致模型在毒性生成和毒性识别能力之间产生权衡。从重度过滤的预训练数据集中训练的模型毒性生成最少，但毒性识别能力也最差。 
    
    ■  对下游任务的影响：对与毒性无关的问答任务性能也有负面影响，可能是由于整体训练数据减少所致。 
    
    ■  逆毒性过滤器的优势：在每个数据集上，逆毒性过滤器对毒性识别的性能最强。因此，在优化毒性识别任务时，应使用逆毒性过滤器。 
    
    ■  预训练策略建议：在预训练阶段，应优先考虑毒性识别能力的提升，而不是过度关注抑制毒性生成。    

# 数据构成 

- 数据源的重要性：数据源的异构性对下游性能的影响至关重要。
  -  异构性的优势：尽管 CC 是 Pile 中最大的文本块，但 Books 和 OpenWeb 虽然较小，但提供了最多样化和预测质量最高的内容。这表明数据的异构性和质量比数据的数量更重要。
  - 针对性数据与异构性的比较：去除与预训练和下游数据来源紧密对齐的领域（如 PubMed、Wikipedia、web 内容等）会对下游性能产生影响，但去除这些针对性领域并不一定比去除大型异构领域（如 CC、OpenWeb 和 Books）对相关下游领域的影响更大。例如，从预训练数据集中去除 CC 会对下游 Academic QA 任务的性能产生更大的降低，而不是去除 Academic 领域本身。  
  - 最佳模型的数据使用：表现最佳的模型通常使用所有或几乎所有的预训练数据来源，这表明开源数据的数量和多样性仍然是当前预训练方法的瓶颈。  
  - 书籍和 Web 数据的特点：Books 和 OpenWeb 数据虽然对毒性识别和生成有较大影响（导致更多的毒性生成），但它们对 QA 任务的积极影响使得在训练中包含这些数据是有益的。 
  - 文本质量特征：书籍文本具有一些独特的特征，如包含高质量文本的同时，也具有最长、最易读、最具毒性和最多个人信息填充的文档。此外，文本质量还可以通过一系列特征来衡量，包括毒性、质量指标、个人可识别信息（PII）、文本统计信息（如平均字长、可读性、类型标记比率、情绪）以及语言类型（非英文）、表情符号和非 ASCII 标点符号的使用情况等。一般来说，非英文、表情符号和非 ASCII 标点符号越多，文本质量可能越低。