# 前言

- 论文原地址： [The Pile: An 800GB Dataset of Diverse Text for Language Modeling](https://arxiv.org/abs/2101.00027)

- 研究表明，增加训练数据集多样性可以提高大规模语言模型的一般跨域知识和下游泛化能力，因此研究人员提出了"The Pile"——一个容量达到825GB的英文文本，专门用于训练大规模的语言模型的数据集。这个数据集是由22个不同的子集组合而成，这些子集既包括现有的数据集，也包含了新创建的数据集。它们来自各种各样的源头，比如学术论文、专业资料、文学作品、对话记录等等。
  

# 数据集构成

"The Pile"数据集由22个子集组成，包括但不限于：
- **Pile-CC**：从Common Crawl中精选的子集，占整个数据集的18.11%，经过了改进的提取质量，以补充其他数据集。
- **PubMed Central**：包含科学文献，特别是医学和生命科学领域的期刊文章，其权重为14.40%，旨在为语言模型提供科学写作的范例。
- **Books3**：书籍文本数据，占12.07%，通过多次展示（epoch），强化模型对文学文本的理解。
- **OpenWebText2**：来自开放网络的文本数据，权重为10.01%，提供了广泛的网络内容，丰富模型对网络语言的掌握。
- **ArXiv**：学术预印本，占8.96%，覆盖物理、数学等多个学科，为模型提供学术写作的样本。
- **Github**：开源代码仓库中的文档和代码注释，占比7.59%，使模型能更好地理解和生成与编程相关的文本。
- **FreeLaw**：法律文件，占比6.12%，有助于模型学习法律术语和法律文本的书写风格。
- **Stack Exchange**：问答网站上的问题和答案，占比5.13%，提供了互动问答形式的数据，增强模型的对话能力。
- **Project Gutenberg**：公共领域的经典文学作品，占比2.17%，为模型提供了古典文学的样本。
- **DeepMind Mathematics**：数学问题，占比1.24%，增强了模型在数学领域的理解和生成能力
- **OpenSubtitles**：电影和电视节目的字幕文本，占比1.55%，增加了娱乐媒体领域的语言数据
- **BookCorpus2**：书籍语料库的扩展，占比0.75%，增加了书籍文本的数据量。
- **Ubuntu IRC**：Ubuntu操作系统的即时通讯记录，占比0.88%，提供了技术交流的样例。
- **EuroParl**：欧洲议会的会议记录，占比0.73%，提供了正式会议记录的样例。
- **YouTube Subtitles**：YouTube视频的字幕，占比0.60%，补充了多媒体内容的文本。
- **PhilPapers**：哲学论文，占比0.38%，提供了哲学领域的学术写作。
- **NIH Grant Abstracts: ExPORTER**：NIH的资助申请摘要，占比0.30%，增加了科学研究申请书的样例。
- **Hacker News**：Hacker News网站上的讨论，占比0.62%，增加了科技和创业领域的话题
- **Enron Emails**：Enron公司的电子邮件，占比0.14%，提供了电子邮件交流的模式。

# 使用The Pile对语言模型进行基准测试
The Pile作为一个旨在训练大规模语言模型的数据集，因其覆盖了多个不同领域的文本而同样适合作为评估模型性能的基准。以下是对使用The Pile进行基准测试的方法和标准的总结：

- 测试方法

  - 数据集划分：The Pile被分为训练、验证和测试三个部分。验证和测试部分各占数据集总量的0.1%，即随机抽取0.1%的数据作为验证和测试集，尽管这仅占数据集的一小部分，但由于数据集本身的庞大，验证和测试集的大小分别达到了1GiB以上。
    
  - 数据去重：尽管已经尽力去除了The Pile内的文档重复，但在训练/验证/测试集之间仍然可能存在少量的重复文档。
    
  - 模型选择：使用GPT-2和GPT-3模型对The Pile的不同组成部分进行测试。GPT-2的所有变体以及通过OpenAI API可用的四个版本的GPT-3均被纳入测试。
    测试集采样：鉴于使用OpenAI API的成本，大部分组成部分的测试集只评估了十分之一的数据。
  
- 测试标准
  - 测试困惑度：计算了GPT-2和GPT-3在The Pile组成部分上的测试困惑度，并将其转换为每UTF-8编码字节的比特数（BPB）。
  - 计算BPB：从给定的负对数似然损失计算BPB时，使用公式$BPB=(LT/LB)*log2(e^l)=(LT/LB)^l/ln(2)$，其中LT表示数据集的标记长度，LB表示数据集的UTF-8编码字节长度。根据The Pile，LT/LB的平均值为0.29335 GPT-2-token/byte。
  - 基准测试指标：首选的度量单位是每UTF-8编码字节的比特数（BPB），因为这一度量标准不受不同标记化方案的影响，并且消除了Unicode字符测量的模糊性。
  
- 测试结果
  - 传统基准测试：在传统语言模型基准测试WikiText上，The Pile表现显著提高，但在LAMBADA上的变化不大。不过，在The Pile自身的各个组成部分上，模型的表现超过了基于Raw CC和CC-100训练的模型。
  
  - 跨域泛化能力：训练于The Pile的模型展示了更强的跨域泛化能力，没有牺牲在传统基准测试上的表现。
  

综上所述，The Pile作为基准测试数据集，通过详细的测试方法和统一的标准，为语言模型的性能提供了全面的评价体系。

# 对‘The Pile’进行评估
为了验证"The Pile"在改进语言建模质量上的有效性，研究者训练了13亿参数的模型，并基于[Brown等人(2020)](Language Models are Few-Shot Learners)的工作设计了架构相同的模型。这些模型在不同的数据集上进行了训练，并在WikiText和LAMBADA任务上进行了评估，这两个任务被视为语言建模能力的基准。此外，还报告了在"The Pile"上的表现，以此作为跨域泛化能力的衡量标准。

为了确保不同大小的数据集之间的公平比较，研究者对评估集中的任何实例进行了去污染处理，使用了与[Brown等人(2020)](Language Models are Few-Shot Learners)相同的13-gram重叠过滤方法，并将数据集缩小到40GB，以控制数据集的大小。特别指出，由于控制了数据集大小，因此对于CC-100(en)来说，该评估相对宽裕，实际上CC-100(en)的大小约为"The Pile"的三分之一。

- 数据集
    研究者比较了以下几个数据集："The Pile"、En、Pile-CC、PubMed Central、Books3、OpenWebText2、ArXiv、Github、FreeLaw、Stack Exchange、USPTO Backgrounds、PubMed Abstracts、Gutenberg(PG-19)、OpenSubtitles、Wikipedia(en)、DM Mathematics、Ubuntu IRC、BookCorpus2、EuroParl、HackerNews、YoutubeSubtitles、PhilPapers 和 NIH ExPorter。
  
- 评价结果
    在"The Pile"上的测试结果显示，对于GPT-2和GPT-3模型，训练数据集"The Pile"在各项指标上的表现都要优于Pile-CC、PubMed Central、Books3、OpenWebText2、ArXiv、Github等数据集。特别是对于GPT-3模型，在"The Pile"上的表现相较于GPT-2有了显著提升。在某些特定数据集上，如ArXiv、Github、PubMed Abstracts等，GPT-3的表现甚至超过了GPT-2在"The Pile"上的表现，这表明GPT-3在这些数据集上的学习能力非常强，以至于额外的训练并没有带来显著的好处。
  
- 小结
    通过对"The Pile"数据集上的语言模型评估，可以看出训练模型使用"The Pile"相较于使用单一来源的数据集（如Common Crawl）在跨域任务上有着更好的表现。同时，该评估也表明了"The Pile"作为一个综合性的数据集，在提升模型泛化能力方面的潜力。
# 调查与记录数据集
随着机器学习研究的发展，人们对训练模型所使用的数据集的规模和多样性越来越关注。尽管在人工智能伦理和偏见研究中已经开始讨论数据集的问题，但在语言模型领域，这一话题尚未引起足够的重视。为了弥补这一不足，本文的研究人员对"The Pile"数据集进行了深入调查和记录。
- 方法
  研究人员采用两种方法来记录"The Pile"数据集：数据表单方法和数据声明方法。这些方法旨在帮助研究人员更好地理解数据集的内容，包括可能存在的问题，并促进对未来数据集的类似调查。

- 特征分析
  研究人员对"The Pile"进行了探索性分析，包括文本长度分布和每个数据集中GPT-2标记的平均字节数。这些分析有助于理解数据集的多样性和质量。

- 多语言内容
  虽然"The Pile"主要关注英文文本，但通过fastText工具分析后发现，其中大约97.4%的内容为英文。然而，由于语言识别的技术限制，无法对低资源语言做出可靠的结论。

- 数据集排除
  在构建"The Pile"过程中，研究者考虑并最终排除了一些数据集，如美国国会记录和某些类型的粉丝小说，主要是出于内容质量和版权问题的考量。

通过这些调查和记录工作的开展，研究人员旨在为未来的用户和研究者提供关于"The Pile"数据集特性的详尽信息，并促进对数据集记录重要性的认识。



  

​    

